
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>Why Devs Love Dynatrace - Episode 3</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://storage.googleapis.com/codelab-elements/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  <google-codelab-analytics gaid="UA-49880327-14"></google-codelab-analytics>
  <google-codelab codelab-gaid=""
                  id="why-devs-love-dynatrace-3"
                  title="Why Devs Love Dynatrace - Episode 3"
                  environment="web"
                  feedback-link="">
    
      <google-codelab-step label="Introduction" duration="1">
        <aside class="special"><p>Stay tuned ðŸ“º for Episode 3</p>
</aside>
<h2 is-upgraded>Abstract of Episode 3</h2>
<p>In this Episode we will compare failed releases that did not pass the QualityGate due performance degradations. We will learn how to compare functional performance tests with each other learning how Dynatrace can pinpoint the degradations up to code-level and we will even decompile the code to understand the bad implementation. One release has a bad calculation implementation and the other a synchronisation issue.</p>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://storage.googleapis.com/codelab-elements/native-shim.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/custom-elements.min.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/prettify.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/codelab-elements.js"></script>

</body>
</html>
